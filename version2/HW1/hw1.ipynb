{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs2Dmtq9fgky",
        "outputId": "78da996b-b2d6-4588-acb7-33f988f58293"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM6l71HeiwXU",
        "outputId": "d4bd96c3-d776-4e79-c345-c93452ed6559"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uCERUSloZ10s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "f66ThQtB0Bar"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n"
      ],
      "metadata": {
        "id": "Ls7dwKkazU2l"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pYWdHWKDTv91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOA2183_Twx_",
        "outputId": "0e9553c8-c2ca-41b7-98c8-5f9da8d32fc9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RRfD1lwbeQEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Create a convolutional neural network model(CNN) :\n",
        "With one separate input layer, three convolutional layers and a maximum pooling layer\n",
        "'''\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input(shape=(224, 224, 3)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flattenning 3D feature maps into 1D vectors\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add full connectivity layer\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# Add Dropout layer to prevent overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer, outputs classification results(there are 15 dog breed categories)\n",
        "model.add(Dense(15, activation='softmax'))\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Printed Model Structures\n",
        "# model.summary()\n",
        "#return model"
      ],
      "metadata": {
        "id": "-u0aTqOyaCb7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yflu3OcDeRB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dir, valid_dir, batch_size, epochs):\n",
        "\n",
        "  # Preprocessing and enhancement of training and validation data\n",
        "  train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "  valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Generating data streams for training and validation sets\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "            train_dir,\n",
        "            target_size=(224, 224),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical'\n",
        "        )\n",
        "\n",
        "  valid_generator = valid_datagen.flow_from_directory(\n",
        "            valid_dir,\n",
        "            target_size=(224, 224),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical'\n",
        "        )\n",
        "\n",
        "  # Training the model\n",
        "  model.fit(\n",
        "            train_generator,\n",
        "            steps_per_epoch=train_generator.samples // batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=valid_generator,\n",
        "            validation_steps=valid_generator.samples // batch_size,\n",
        "        )\n",
        "\n",
        "\n",
        "  print(321321)\n",
        "\n",
        "  # Calculating accuracy\n",
        "  scores = model.evaluate(\n",
        "            valid_generator, steps=valid_generator.samples // batch_size)\n",
        "  validation_accuracy = scores[1] * 100\n",
        "\n",
        "\n",
        "  print(\"\\nValid set Accuracy: %.2f%%\\n\" % validation_accuracy)\n",
        "  print(123333)"
      ],
      "metadata": {
        "id": "KHe-avw7bZrv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KO5_ymTLeR2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(valid_dir, batch_size):\n",
        "\n",
        "  # Preprocessing and enhancement of validation data\n",
        "  valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Generating data streams for validation sets\n",
        "  valid_generator = valid_datagen.flow_from_directory(\n",
        "            valid_dir,\n",
        "            target_size=(224, 224),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical'\n",
        "        )\n",
        "\n",
        "  # Calculating accuracy\n",
        "  scores = model.evaluate(\n",
        "            valid_generator, steps=valid_generator.samples // batch_size)\n",
        "  validation_accuracy = scores[1] * 100\n",
        "\n",
        "  #print(\"\\nValid set Accuracy: %.2f%%\\n\" % validation_accuracy)\n"
      ],
      "metadata": {
        "id": "0Pnq3KIYbiqk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5RzN1BbYeSn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def center_crop_image(img):\n",
        "  '''\n",
        "  Pre-processing of images, with different sized images as input,\n",
        "          and centered cropped images as output.\n",
        "  '''\n",
        "\n",
        "  width, height = img.size\n",
        "  new_width = new_height = min(width, height)\n",
        "  left = (width - new_width) // 2\n",
        "  top = (height - new_height) // 2\n",
        "  right = (width + new_width) // 2\n",
        "  bottom = (height + new_height) // 2\n",
        "\n",
        "  return img.crop((left, top, right, bottom))"
      ],
      "metadata": {
        "id": "6KWjLmV8bvdt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_Z-aG56VeTDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predicted_breed(self, predictions):\n",
        "  '''\n",
        "  To get the dog breed name based on the model predictions,\n",
        "  assume that predictions is the result of the model's prediction of the image,\n",
        "  determine the predicted breed based on the index of the highest probability in the probability vector\n",
        "  '''\n",
        "\n",
        "  class_names = [\"Airedale\", \"Beagle\", \"Bloodhound\", \"Bluetick\", \"Chihuahua\", \"Collie\", \"Dingo\",\n",
        "                            \"French Bulldog\", \"German Sheperd\", \"Malinois\", \"Newfoundland\", \"Pekinese\",\n",
        "                            \"Pomeranian\", \"Pug\", \"Vizsla\"]\n",
        "\n",
        "  breed_index = predictions.argmax()\n",
        "  breed_name = class_names[breed_index]\n",
        "\n",
        "  return breed_name"
      ],
      "metadata": {
        "id": "H4pgwTMZb1Re"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qHawuyEeeTxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_dir):\n",
        "\n",
        "  # Getting test set file address\n",
        "  test_files = os.listdir(test_dir)\n",
        "  # To be fair, the order of access is randomized.\n",
        "  random.shuffle(test_files)\n",
        "\n",
        "  test_results = []\n",
        "\n",
        "  for file_name in test_files:\n",
        "\n",
        "    # Load image with center crop and preprocessing\n",
        "    img_path = os.path.join(test_dir, file_name)\n",
        "    img = Image.open(img_path)\n",
        "    # Center Cropped Image\n",
        "    img = center_crop_image(img)\n",
        "    # resize\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    img_array = img_array.reshape((1,) + img_array.shape)\n",
        "\n",
        "    # Making predictions about the image\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_breed = get_predicted_breed(predictions)\n",
        "\n",
        "    test_results.append((file_name, predicted_breed))\n",
        "\n",
        "    # Output results into Excel(no need title)\n",
        "    df = pd.DataFrame(test_results, columns=[\n",
        "                          'File Name', 'Predicted Breed'])\n",
        "    df.to_excel('test_data.xlsx', index=False, header=False)\n",
        "\n",
        "    #s = \"Test results saved to test_data.xlsx\"\n",
        "    #s"
      ],
      "metadata": {
        "id": "WQy9Mqhdb6bf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "muN5HkBFeUyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    train_dir = '/content/drive/MyDrive/archive/train'\n",
        "    valid_dir = '/content/drive/MyDrive/archive/valid'\n",
        "    test_dir = '/content/drive/MyDrive/archive/testing_set'\n",
        "    batch_size = 32\n",
        "    epochs = 10\n",
        "\n",
        "    #build_model()\n",
        "    train(train_dir, valid_dir, batch_size, epochs)\n",
        "    #evaluate(valid_dir, batch_size)\n",
        "    #test(test_dir)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "OCRuSHPaeKYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe20b63b-53ff-4b69-8d32-1e58b412124d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1714 images belonging to 15 classes.\n",
            "Found 150 images belonging to 15 classes.\n",
            "Epoch 1/10\n",
            "53/53 [==============================] - 21s 390ms/step - loss: 0.5278 - accuracy: 0.8163 - val_loss: 1.5646 - val_accuracy: 0.5156\n",
            "Epoch 2/10\n",
            "53/53 [==============================] - 20s 379ms/step - loss: 0.5013 - accuracy: 0.8484 - val_loss: 1.5268 - val_accuracy: 0.5469\n",
            "Epoch 3/10\n",
            "53/53 [==============================] - 20s 379ms/step - loss: 0.4965 - accuracy: 0.8389 - val_loss: 1.6114 - val_accuracy: 0.5625\n",
            "Epoch 4/10\n",
            "53/53 [==============================] - 21s 391ms/step - loss: 0.3984 - accuracy: 0.8686 - val_loss: 1.6707 - val_accuracy: 0.5391\n",
            "Epoch 5/10\n",
            "53/53 [==============================] - 20s 382ms/step - loss: 0.4678 - accuracy: 0.8567 - val_loss: 1.6312 - val_accuracy: 0.5547\n",
            "Epoch 6/10\n",
            "53/53 [==============================] - 21s 389ms/step - loss: 0.4243 - accuracy: 0.8644 - val_loss: 1.6175 - val_accuracy: 0.5703\n",
            "Epoch 7/10\n",
            "53/53 [==============================] - 20s 380ms/step - loss: 0.3731 - accuracy: 0.8805 - val_loss: 1.5095 - val_accuracy: 0.5781\n",
            "Epoch 8/10\n",
            "53/53 [==============================] - 20s 385ms/step - loss: 0.3723 - accuracy: 0.8835 - val_loss: 1.4382 - val_accuracy: 0.5859\n",
            "Epoch 9/10\n",
            "53/53 [==============================] - 21s 388ms/step - loss: 0.3994 - accuracy: 0.8775 - val_loss: 1.5753 - val_accuracy: 0.5781\n",
            "Epoch 10/10\n",
            "53/53 [==============================] - 20s 381ms/step - loss: 0.3222 - accuracy: 0.8930 - val_loss: 1.5630 - val_accuracy: 0.6094\n",
            "321321\n",
            "4/4 [==============================] - 0s 98ms/step - loss: 1.5617 - accuracy: 0.6016\n",
            "\n",
            "Valid set Accuracy: 60.16%\n",
            "\n",
            "123333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfvICLQ1NG0B",
        "outputId": "2fe4609d-1760-48d4-ddd1-54ec944c1282"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 12 09:20:34 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0              41W / 300W |   4430MiB / 16384MiB |      6%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}