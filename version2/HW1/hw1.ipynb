{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs2Dmtq9fgky",
        "outputId": "09ad203a-11f4-4246-ff5e-3d44d5b62cbd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "KM6l71HeiwXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "uCERUSloZ10s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "f66ThQtB0Bar"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n"
      ],
      "metadata": {
        "id": "Ls7dwKkazU2l"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pYWdHWKDTv91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOA2183_Twx_",
        "outputId": "8e676bdd-6c63-405f-b891-fbaf772e4fd6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RRfD1lwbeQEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(self):\n",
        "  '''\n",
        "  Create a convolutional neural network model(CNN) :\n",
        "  With one separate input layer, three convolutional layers and a maximum pooling layer\n",
        "  '''\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Input(shape=(224, 224, 3)))\n",
        "\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  # Flattenning 3D feature maps into 1D vectors\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # Add full connectivity layer\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "\n",
        "  # Add Dropout layer to prevent overfitting\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  # Output layer, outputs classification results(there are 15 dog breed categories)\n",
        "  model.add(Dense(15, activation='softmax'))\n",
        "\n",
        "  # compiling the model\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "  # Printed Model Structures\n",
        "  # model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "-u0aTqOyaCb7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yflu3OcDeRB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dir, valid_dir, batch_size, epochs):\n",
        "\n",
        "  # Preprocessing and enhancement of training and validation data\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "  valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Generating data streams for training and validation sets\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "            train_dir,\n",
        "            target_size=(224, 224),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical'\n",
        "        )\n",
        "\n",
        "  valid_generator = valid_datagen.flow_from_directory(\n",
        "            valid_dir,\n",
        "            target_size=(224, 224),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical'\n",
        "        )\n",
        "\n",
        "  # Training the model\n",
        "  model.fit(\n",
        "            train_generator,\n",
        "            steps_per_epoch=train_generator.samples // batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=valid_generator,\n",
        "            validation_steps=valid_generator.samples // batch_size,\n",
        "        )"
      ],
      "metadata": {
        "id": "KHe-avw7bZrv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KO5_ymTLeR2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(self, valid_dir, batch_size):\n",
        "\n",
        "  # Preprocessing and enhancement of validation data\n",
        "  valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Generating data streams for validation sets\n",
        "  valid_generator = valid_datagen.flow_from_directory(\n",
        "            valid_dir,\n",
        "            target_size=(224, 224),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical'\n",
        "        )\n",
        "\n",
        "  # Calculating accuracy\n",
        "  scores = self.model.evaluate(\n",
        "            valid_generator, steps=valid_generator.samples // batch_size)\n",
        "  validation_accuracy = scores[1] * 100\n",
        "\n",
        "  print(\"\\nValid set Accuracy: %.2f%%\\n\" % validation_accuracy)\n"
      ],
      "metadata": {
        "id": "0Pnq3KIYbiqk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5RzN1BbYeSn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def center_crop_image(self, img):\n",
        "  '''\n",
        "  Pre-processing of images, with different sized images as input,\n",
        "          and centered cropped images as output.\n",
        "  '''\n",
        "\n",
        "  width, height = img.size\n",
        "  new_width = new_height = min(width, height)\n",
        "  left = (width - new_width) // 2\n",
        "  top = (height - new_height) // 2\n",
        "  right = (width + new_width) // 2\n",
        "  bottom = (height + new_height) // 2\n",
        "\n",
        "  return img.crop((left, top, right, bottom))"
      ],
      "metadata": {
        "id": "6KWjLmV8bvdt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_Z-aG56VeTDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predicted_breed(self, predictions):\n",
        "  '''\n",
        "  To get the dog breed name based on the model predictions,\n",
        "  assume that predictions is the result of the model's prediction of the image,\n",
        "  determine the predicted breed based on the index of the highest probability in the probability vector\n",
        "  '''\n",
        "\n",
        "  class_names = [\"Airedale\", \"Beagle\", \"Bloodhound\", \"Bluetick\", \"Chihuahua\", \"Collie\", \"Dingo\",\n",
        "                            \"French Bulldog\", \"German Sheperd\", \"Malinois\", \"Newfoundland\", \"Pekinese\",\n",
        "                            \"Pomeranian\", \"Pug\", \"Vizsla\"]\n",
        "\n",
        "  breed_index = predictions.argmax()\n",
        "  breed_name = class_names[breed_index]\n",
        "\n",
        "  return breed_name"
      ],
      "metadata": {
        "id": "H4pgwTMZb1Re"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qHawuyEeeTxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(self, test_dir):\n",
        "\n",
        "  # Getting test set file address\n",
        "  test_files = os.listdir(test_dir)\n",
        "  # To be fair, the order of access is randomized.\n",
        "  random.shuffle(test_files)\n",
        "\n",
        "  test_results = []\n",
        "\n",
        "  for file_name in test_files:\n",
        "\n",
        "    # Load image with center crop and preprocessing\n",
        "    img_path = os.path.join(test_dir, file_name)\n",
        "    img = Image.open(img_path)\n",
        "    # Center Cropped Image\n",
        "    img = self.center_crop_image(img)\n",
        "    # resize\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    img_array = img_array.reshape((1,) + img_array.shape)\n",
        "\n",
        "    # Making predictions about the image\n",
        "    predictions = self.model.predict(img_array)\n",
        "    predicted_breed = self.get_predicted_breed(predictions)\n",
        "\n",
        "    test_results.append((file_name, predicted_breed))\n",
        "\n",
        "    # Output results into Excel(no need title)\n",
        "    df = pd.DataFrame(test_results, columns=[\n",
        "                          'File Name', 'Predicted Breed'])\n",
        "    df.to_excel('test_data.xlsx', index=False, header=False)\n",
        "    print(\"Test results saved to test_data.xlsx\")"
      ],
      "metadata": {
        "id": "WQy9Mqhdb6bf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "muN5HkBFeUyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    train_dir = 'archive/train'\n",
        "    valid_dir = 'archive/valid'\n",
        "    test_dir = 'archive/testing_set'\n",
        "    batch_size = 32\n",
        "    epochs = 10\n",
        "\n",
        "    train(train_dir, valid_dir, batch_size, epochs)\n",
        "    #evaluate(valid_dir, batch_size)\n",
        "    #test(test_dir)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "OCRuSHPaeKYn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "206e348b-6115-47d9-d136-a5258300caac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ImageDataGenerator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7a53aedaea11>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-7a53aedaea11>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m#evaluate(valid_dir, batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#test(test_dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-e40dbb5cf5b4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dir, valid_dir, batch_size, epochs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# Preprocessing and enhancement of training and validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mvalid_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}