{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs2Dmtq9fgky",
        "outputId": "09ad203a-11f4-4246-ff5e-3d44d5b62cbd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "KM6l71HeiwXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uCERUSloZ10s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "f66ThQtB0Bar"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n"
      ],
      "metadata": {
        "id": "Ls7dwKkazU2l"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pYWdHWKDTv91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOA2183_Twx_",
        "outputId": "41e336b3-d94a-4de0-d9b3-0b6bfcc5a31b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RRfD1lwbeQEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Create a convolutional neural network model(CNN) :\n",
        "With one separate input layer, three convolutional layers and a maximum pooling layer\n",
        "'''\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input(shape=(224, 224, 3)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flattenning 3D feature maps into 1D vectors\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add full connectivity layer\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# Add Dropout layer to prevent overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer, outputs classification results(there are 15 dog breed categories)\n",
        "model.add(Dense(15, activation='softmax'))\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Printed Model Structures\n",
        "# model.summary()\n",
        "#return model"
      ],
      "metadata": {
        "id": "-u0aTqOyaCb7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yflu3OcDeRB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dir, valid_dir, batch_size, epochs):\n",
        "\n",
        "  # Preprocessing and enhancement of training and validation data\n",
        "  train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "  valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Generating data streams for training and validation sets\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "            train_dir,\n",
        "            target_size=(224, 224),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical'\n",
        "        )\n",
        "\n",
        "  valid_generator = valid_datagen.flow_from_directory(\n",
        "            valid_dir,\n",
        "            target_size=(224, 224),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical'\n",
        "        )\n",
        "\n",
        "  # Training the model\n",
        "  model.fit(\n",
        "            train_generator,\n",
        "            steps_per_epoch=train_generator.samples // batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=valid_generator,\n",
        "            validation_steps=valid_generator.samples // batch_size,\n",
        "        )\n",
        "\n",
        "  # Calculating accuracy\n",
        "  scores = model.evaluate(\n",
        "            valid_generator, steps=valid_generator.samples // batch_size)\n",
        "  validation_accuracy = scores[1] * 100\n",
        "\n",
        "  print(\"\\nValid set Accuracy: %.2f%%\\n\" % validation_accuracy)"
      ],
      "metadata": {
        "id": "KHe-avw7bZrv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KO5_ymTLeR2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(valid_dir, batch_size):\n",
        "\n",
        "  # Preprocessing and enhancement of validation data\n",
        "  valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Generating data streams for validation sets\n",
        "  valid_generator = valid_datagen.flow_from_directory(\n",
        "            valid_dir,\n",
        "            target_size=(224, 224),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical'\n",
        "        )\n",
        "\n",
        "  # Calculating accuracy\n",
        "  scores = model.evaluate(\n",
        "            valid_generator, steps=valid_generator.samples // batch_size)\n",
        "  validation_accuracy = scores[1] * 100\n",
        "\n",
        "  print(\"\\nValid set Accuracy: %.2f%%\\n\" % validation_accuracy)\n"
      ],
      "metadata": {
        "id": "0Pnq3KIYbiqk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5RzN1BbYeSn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def center_crop_image(img):\n",
        "  '''\n",
        "  Pre-processing of images, with different sized images as input,\n",
        "          and centered cropped images as output.\n",
        "  '''\n",
        "\n",
        "  width, height = img.size\n",
        "  new_width = new_height = min(width, height)\n",
        "  left = (width - new_width) // 2\n",
        "  top = (height - new_height) // 2\n",
        "  right = (width + new_width) // 2\n",
        "  bottom = (height + new_height) // 2\n",
        "\n",
        "  return img.crop((left, top, right, bottom))"
      ],
      "metadata": {
        "id": "6KWjLmV8bvdt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_Z-aG56VeTDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predicted_breed(self, predictions):\n",
        "  '''\n",
        "  To get the dog breed name based on the model predictions,\n",
        "  assume that predictions is the result of the model's prediction of the image,\n",
        "  determine the predicted breed based on the index of the highest probability in the probability vector\n",
        "  '''\n",
        "\n",
        "  class_names = [\"Airedale\", \"Beagle\", \"Bloodhound\", \"Bluetick\", \"Chihuahua\", \"Collie\", \"Dingo\",\n",
        "                            \"French Bulldog\", \"German Sheperd\", \"Malinois\", \"Newfoundland\", \"Pekinese\",\n",
        "                            \"Pomeranian\", \"Pug\", \"Vizsla\"]\n",
        "\n",
        "  breed_index = predictions.argmax()\n",
        "  breed_name = class_names[breed_index]\n",
        "\n",
        "  return breed_name"
      ],
      "metadata": {
        "id": "H4pgwTMZb1Re"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qHawuyEeeTxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_dir):\n",
        "\n",
        "  # Getting test set file address\n",
        "  test_files = os.listdir(test_dir)\n",
        "  # To be fair, the order of access is randomized.\n",
        "  random.shuffle(test_files)\n",
        "\n",
        "  test_results = []\n",
        "\n",
        "  for file_name in test_files:\n",
        "\n",
        "    # Load image with center crop and preprocessing\n",
        "    img_path = os.path.join(test_dir, file_name)\n",
        "    img = Image.open(img_path)\n",
        "    # Center Cropped Image\n",
        "    img = center_crop_image(img)\n",
        "    # resize\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    img_array = img_array.reshape((1,) + img_array.shape)\n",
        "\n",
        "    # Making predictions about the image\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_breed = get_predicted_breed(predictions)\n",
        "\n",
        "    test_results.append((file_name, predicted_breed))\n",
        "\n",
        "    # Output results into Excel(no need title)\n",
        "    df = pd.DataFrame(test_results, columns=[\n",
        "                          'File Name', 'Predicted Breed'])\n",
        "    df.to_excel('test_data.xlsx', index=False, header=False)\n",
        "    print(\"Test results saved to test_data.xlsx\")"
      ],
      "metadata": {
        "id": "WQy9Mqhdb6bf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "muN5HkBFeUyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    train_dir = '/content/drive/MyDrive/archive/train'\n",
        "    valid_dir = '/content/drive/MyDrive/archive/valid'\n",
        "    test_dir = '/content/drive/MyDrive/archive/testing_set'\n",
        "    batch_size = 32\n",
        "    epochs = 10\n",
        "\n",
        "    #build_model()\n",
        "    train(train_dir, valid_dir, batch_size, epochs)\n",
        "    #evaluate(valid_dir, batch_size)\n",
        "    #test(test_dir)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "OCRuSHPaeKYn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}